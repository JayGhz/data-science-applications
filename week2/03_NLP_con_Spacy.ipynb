{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5nCinsekxQ"
      },
      "source": [
        "# Conceptos para el Procesamiento del Lenguaje Natural con spaCy\n",
        "\n",
        "* ***spaCy*** es una librería de código abierto en python para el Procesamiento del Lenguaje natural que posee modelos entrenados para varios idiomas, entre ellos el Español.\n",
        "\n",
        "\n",
        "* Es una librería pensada para funcionar en entornos productivos y es una librería con mejor rendimiento que **NLTK**.\n",
        "\n",
        "\n",
        "* Dispone de una web y de una documentación muy buena, incluso se pueden ejecutar ciertos ejemplos en la propia web: https://spacy.io/\n",
        "\n",
        "\n",
        "* Dispone también de un curso online (https://course.spacy.io/) bastante interesante.\n",
        "\n",
        "\n",
        "* Entre otras cosas con ***spaCy*** podemos hacer:\n",
        "    1. Tokenización\n",
        "    2. Lematización\n",
        "    3. Detección de Stop Words\n",
        "    4. Part of Speech (PoS)\n",
        "    5. Named Entity Recognition (NER)\n",
        "\n",
        "\n",
        "* ***spaCy*** puede ser instalado tanto con \"pip\" como con \"conda\" de la siguiente manera respectivamente:\n",
        "\n",
        "```\n",
        ">> pip install spacy\n",
        ">> conda install spacy\n",
        "```\n",
        "\n",
        "\n",
        "* Como se ha comentado anteriormente la ventaja que tiene ***spaCy*** frente a ***NLTK*** en lo que a idiomas se refiere es que permite trabajar con varior idiomas gracias a los modelos que tiene entrenados.\n",
        "\n",
        "\n",
        "* En particular para el Español ***spaCy*** tiene entrenados dos modelos (con Redes Neuronales Convolucionales según su documentación) de pequeño y mediano tamaño con los corpus de **AnCora** (http://clic.ub.edu/corpus/es/ancora) y **WikiNER**.\n",
        "\n",
        "\n",
        "* Estos dos modelos de pequeño y mediano tamaño los podemos encontrar en la web de ***spaCy*** (https://spacy.io/models/es) y son los siguientes:\n",
        "    - es_core_news_md (93 MiB)\n",
        "    - es_core_news_sm (35 MiB)\n",
        "\n",
        "\n",
        "* ***spaCy*** hace uso de estos modelos y tienen que ser descargados, para ello debemos de abrir un terminal en python y ejecutar lo siguiente para descargar el modelo en Español (*NOTA: los que uséis conda, tener activado el entorno*).\n",
        "\n",
        "\n",
        "```\n",
        ">> python3 -m spacy download es\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBGpB5mNekxU",
        "outputId": "04f4e8bd-9fe7-4a11-d650-0d21c18debd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (0.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.32.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (80.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jayka\\onedrive\\documentos\\courses\\data-science-applications\\env\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
            "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "     ------------------------------- ------- 10.5/12.9 MB 74.7 MB/s eta 0:00:01\n",
            "     --------------------------------------- 12.9/12.9 MB 44.0 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install spacy\n",
        "! python -m spacy download es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2YzlBPekxV"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "# spaCy - Arquitectura:\n",
        "\n",
        "* ***spaCy*** utiliza dos tipos de estructuras (objetos) llamados **Doc** y **Vocab**:\n",
        "<span></span><br><br>\n",
        "    - ***Doc***: Este objeto esta formado por una secuencia de Tokens (objetos de la clase ***Token***).\n",
        "<span></span><br><br>\n",
        "    - ***Vocab***: Este objeto posee un conjunto de Look-up tables (tablas de consulta) que hacen que la información común esté disponible en todos los documentos (Lemas, Stop Words, PoS, etc.).\n",
        "\n",
        "<img src=\"./imgs/006_spacy_architecture.png\" style=\"width: 600px;\"/>\n",
        "\n",
        "\n",
        "* Una forma sencilla de trabajar con ***spaCy*** es:\n",
        "    1. Cargar un modelo de lenguaje (por ejemplo el Español)\n",
        "    2. Dado un texto plano, crear un objeto de la clase \"Doc\" y pasarle el texto plano. El texto ya quedará tokenizado dentro del objeto \"Doc\".\n",
        "    3. Trabajar sobre las palabras del documento.\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "\n",
        "# Ejemplos con spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF0Pm-SmekxW"
      },
      "source": [
        "## -Tokenización\n",
        "\n",
        "\n",
        "* Divide las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
        "\n",
        "\n",
        "* Pasos:\n",
        "    1. Importar la librería.\n",
        "    2. Cargar un modelo de lenguaje (el Español).\n",
        "    3. Crear un documento (de la clase \"Doc\") pasándole un texto plano.\n",
        "    4. El objeto de la clase \"Doc\" ya esta tokenizado por palabras y podemos iterar sobre él."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKrgMyzlekxW",
        "outputId": "4ef80568-bd45-4415-b101-632041c3767c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo de dato: <class 'spacy.tokens.doc.Doc'>\n",
            "['La', 'UPC', 'es', 'una', 'institución', 'educativa', 'basada', 'en', 'la', 'exigencia', 'e', 'innovación', 'orientada', 'a', 'formar', 'a', 'líderes', 'íntegros', 'que', 'transformen', 'el', 'Perú', '.']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"La UPC es una institución educativa basada en la exigencia e innovación orientada a formar a líderes íntegros que transformen el Perú.\")\n",
        "print('Tipo de dato: ' + str(type(doc)))\n",
        "print([w.text for w in doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzwUwpauekxX"
      },
      "source": [
        "## -Segmentación\n",
        "\n",
        "\n",
        "* La ***segmentación*** divide las cadenas de texto en frases o párrafos.\n",
        "\n",
        "\n",
        "* Para la segmentación en spaCy hay que usar un componente llamado \"**sentencier**\" que divide los textos por simbolos como puntos, interrogantes, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_W2EAI_ekxX",
        "outputId": "982749e3-cf42-4215-a3df-36b69fb03f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Frase numero 1.', 'Frase número 2?', 'Frase 3']\n"
          ]
        }
      ],
      "source": [
        "from spacy.pipeline import Sentencizer\n",
        "sentencizer = Sentencizer()\n",
        "doc = nlp(\"Frase numero 1. Frase número 2? Frase 3\")\n",
        "print([s.text for s in doc.sents])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q19ZzhZekxY"
      },
      "source": [
        "## -Stemming\n",
        "\n",
        "* ***Funcionalidad no disponoble en spaCy***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kd_zo5mekxY"
      },
      "source": [
        "## -Lematización\n",
        "\n",
        "\n",
        "* Proceso lingüístico que sustituye una palabra con forma flexionada (plurales, femeninos, verbos conjugados, etc.) por su lema; es decir, por una palabra válida en el idioma.\n",
        "\n",
        "\n",
        "* ***spaCy*** hace una lematización muy buena en Español.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen la propiedad (o atributo) ***lema_*** que nos devuelve el lema del token (o la palabra)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrPiKqqRekxZ",
        "outputId": "1125375f-4768-4dd6-89f8-7b648248669b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La - el\n",
            "UPC - UPC\n",
            "es - ser\n",
            "una - uno\n",
            "institución - institución\n",
            "educativa - educativo\n",
            "basada - basado\n",
            "en - en\n",
            "la - el\n",
            "exigencia - exigencia\n",
            "e - e\n",
            "innovación - innovación\n",
            "orientada - orientado\n",
            "a - a\n",
            "formar - formar\n",
            "a - a\n",
            "líderes - líder\n",
            "íntegros - íntegro\n",
            "que - que\n",
            "transformen - transformir\n",
            "el - el\n",
            "Perú - Perú\n",
            ". - .\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"La UPC es una institución educativa basada en la exigencia e innovación orientada a formar a líderes íntegros que transformen el Perú.\")\n",
        "for word in doc:\n",
        "    print(word.text + ' - ' + word.lemma_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxE1UqciekxZ"
      },
      "source": [
        "## -Stop words\n",
        "\n",
        "* Son las palabras que no aportan nada al significado de la frase.\n",
        "\n",
        "\n",
        "* spaCy dispone de más de 500 stop words en Español.\n",
        "\n",
        "\n",
        "* Veamos a continuación las Stop Words en Español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvrucUGgekxa",
        "outputId": "b9536f53-8c49-49d4-f176-1fd25ef5bbbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de stop words: 521\n",
            "Stop words: ['cinco', 'vosotras', 'tengo', 'mios', 'estais', 'sido', 'para', 'habían', 'podrían', 'será', 'pasada', 'habrá', 'quien', 'partir', 'mis', 'cuándo', 'hacemos', 'tambien', 'algunos', 'deprisa', 'dio', 'sabe', 'medio', 'mucho', 'llegó', 'míos', 'estas', 'hacerlo', 'vuestra', 'proximo', 'estaba', 'dejó', 'quienes', 'mal', 'somos', 'indicó', 'consideró', 'nuestra', 'cada', 'nuevas', 'tampoco', 'último', 'todavía', 'total', 'usais', 'estamos', 'sería', 'encuentra', 'pocos', 'segunda', 'han', 'los', 'agregó', 'arriba', 'dos', 'afirmó', 'son', 'mismo', 'tercero', 'poco', 'deben', 'hacer', 'incluso', 'señaló', 'soy', 'quién', 'últimas', 'ustedes', 'serán', 'eramos', 'estados', 'manera', 'cierta', 'saben', 'una', 'tenemos', 'once', 'aquellos', 'esos', 'podriamos', 'veces', 'adelante', 'vez', 'asi', 'contra', 'su', 'aseguró', 'cualquier', 'podeis', 'el', 'usar', 'lo', 'usas', 'aquello', 'podriais', 'ir', 'habla', 'usamos', 'porque', 'tus', 'doce', 'esas', 'salvo', 'tuvo', 'donde', 'todo', 'hace', 'tener', 'ellas', 'vuestros', 'estará', 'mencionó', 'podrán', 'todavia', 'y', 'podemos', 'siete', 'tenga', 'sino', 'acuerdo', 'cuantos', 'así', 'mío', 'enfrente', 'ése', 'tú', 'va', 'cuales', 'sigue', 'sois', 'diferente', 'poder', 'vamos', 'mientras', 'un', 'igual', 'éstas', 'eras', 'propia', 'pesar', 'tuyos', 'mí', 'ciertas', 'ahi', 'entre', 'cuenta', 'me', 'aproximadamente', 'están', 'estado', 'primero', 'se', 'según', 'repente', 'pasado', 'dan', 'también', 'siguiente', 'unos', 'nada', 'era', 'quiza', 'tu', 'nadie', 'usan', 'este', 'solamente', 'hacen', 'lleva', 'pocas', 'pues', 'ningunas', 'de', 'había', 'sera', 'está', 'suyos', 'hoy', 'hemos', 'estuvo', 'mas', 'ningunos', 'tarde', 'consiguen', 'ningún', 'diez', 'través', 'ya', 'sí', 'trata', 'éstos', 'podria', 'puedo', 'conseguir', 'cuántos', 'tanto', 'durante', 'dias', 'últimos', 'ahora', 'ellos', 'claro', 'ello', 'podrá', 'eres', 'muchas', 'nosotras', 'puede', 'hay', 'creo', 'excepto', 'todos', 'bien', 'hubo', 'cuanta', 'debajo', 'les', 'aquél', 'queremos', 'sé', 'fuera', 'fuimos', 'usted', 'anterior', 'primera', 'haces', 'despues', 'embargo', 'suya', 'paìs', 'eran', 'solo', 'detras', 'tan', 'primeros', 'hecho', 'ninguna', 'tuya', 'pueden', 'nueva', 'quedó', 'no', 'solos', 'hablan', 'nos', 'fui', 'propias', 'mio', 'consigue', 'dónde', 'e', 'estaban', 'tenía', 'respecto', 'debido', 'ti', 'grandes', 'hizo', 'van', 'verdadera', 'segun', 'qué', 'algunas', 'expresó', 'tercera', 'casi', 'algún', 'cuál', 'primer', 'pronto', 'quiere', 'saber', 'conmigo', 'buena', 'sus', 'tras', 'otro', 'toda', 'sea', 'yo', 'misma', 'mayor', 'cuáles', 'propios', 'esto', 'otra', 'propio', 'muy', 'tres', 'estoy', 'ser', 'buen', 'parece', 'aquel', 'grande', 'haya', 'más', 'aquella', 'podría', 'seis', 'cuatro', 'haber', 'podrian', 'aqui', 'delante', 'vuestras', 'mi', 'buenas', 'algo', 'tienen', 'dijeron', 'apenas', 'muchos', 'otras', 'mias', 'pero', 'nuestras', 'vuestro', 'próximos', 'cuantas', 'parte', 'conocer', 'eso', 'aunque', 'ésa', 'varias', 'aquí', 'u', 'bueno', 'o', 'ademas', 'ahí', 'suyo', 'otros', 'bastante', 'haceis', 'podrias', 'nueve', 'realizado', 'unas', 'verdad', 'ambos', 'todas', 'siempre', 'antes', 'sin', 'ni', 'mismos', 'hasta', 'segundo', 'mia', 'breve', 'mejor', 'próximo', 'al', 'solas', 'dentro', 'le', 'conseguimos', 'ese', 'sabeis', 'aún', 'voy', 'estos', 'además', 'quiénes', 'explicó', 'pudo', 'esta', 'nuevo', 'tuyo', 'nuestro', 'la', 'nuevos', 'aun', 'varios', 'mía', 'desde', 'junto', 'fueron', 'existen', 'despacio', 'qeu', 'lado', 'del', 'modo', 'bajo', 'esa', 'he', 'alli', 'última', 'hago', 'habia', 'peor', 'largo', 'dicho', 'cierto', 'haciendo', 'ésta', 'gran', 'da', 'tenido', 'aquellas', 'luego', 'enseguida', 'las', 'realizó', 'tal', 'diferentes', 'estar', 'cómo', 'cuánto', 'él', 'menudo', 'aquéllos', 'ella', 'ésos', 'tiene', 'buenos', 'vosotros', 'cuántas', 'contigo', 'ésas', 'que', 'realizar', 'demasiado', 'alguna', 'tuyas', 'tendrá', 'ver', 'alrededor', 'ocho', 'nosotros', 'atras', 'fin', 'ante', 'estan', 'entonces', 'cuanto', 'dice', 'consigo', 'dieron', 'vais', 'poner', 'usa', 'añadió', 'pueda', 'sola', 'dado', 'dijo', 'ciertos', 'sean', 'uno', 'consigues', 'nunca', 'debe', 'ha', 'ultimo', 'encima', 'en', 'sabes', 'comentó', 'siendo', 'como', 'demás', 'quizá', 'sólo', 'detrás', 'cual', 'cuánta', 'ninguno', 'aquélla', 'informo', 'días', 'dicen', 'supuesto', 'éste', 'considera', 'tendrán', 'hicieron', 'informó', 'mismas', 'uso', 'manifestó', 'día', 'temprano', 'allí', 'a', 'dar', 'menos', 'después', 'posible', 'aquéllas', 'mucha', 'teneis', 'final', 'por', 'vaya', 'nuestros', 'alguno', 'sobre', 'suyas', 'quizás', 'te', 'dia', 'verdadero', 'llevar', 'decir', 'cuando', 'con', 'existe', 'hacia', 'si', 'es', 'os', 'poca', 'mediante', 'mías', 'sabemos', 'fue', 'quizas']\n"
          ]
        }
      ],
      "source": [
        "stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "print('Número de stop words: ' + str(len(stopwords)))\n",
        "print('Stop words: ' + str(list(stopwords)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjDpe2hHekxa"
      },
      "source": [
        "* Los objetos de la clase ***Token*** tienen la propiedad ***is_stop*** que devuelve en Boolean indicando si el token es o no una stop word; es decir, si el ***Token*** (o palabra) esta dentro de la lista antes mostrada.\n",
        "\n",
        "\n",
        "* Veamos a continuación como obtener las stop words de una frase con spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAQWkNJIekxa",
        "outputId": "8c668a74-b75c-4c15-8037-ac0502c5c32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La\n",
            "es\n",
            "una\n",
            "en\n",
            "la\n",
            "e\n",
            "a\n",
            "a\n",
            "que\n",
            "el\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"La UPC es una institución educativa basada en la exigencia e innovación orientada a formar a líderes íntegros que transformen el Perú.\")\n",
        "for word in doc:\n",
        "    if word.is_stop:\n",
        "        print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtmRl8fRekxb"
      },
      "source": [
        "## -Part of Speech (PoS)\n",
        "\n",
        "* En ***spaCy*** el PoS lo divide en 3 tipos de tags que son:\n",
        "    1. **pos**: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
        "    2. **tag**: etiqueta con más nivel de detalle que el pos.\n",
        "    3. **dep**: dependencia sintáctica para ver la relación entre tokens.\n",
        "\n",
        "\n",
        "* Estos 3 tipos son propiedades de la clase ***Token***:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "bc439wb1ekxb",
        "outputId": "3d1304b0-4e6b-411d-dd97-76ef40e35d00",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UPC</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>es</td>\n",
              "      <td>AUX</td>\n",
              "      <td>AUX</td>\n",
              "      <td>cop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>una</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>institución</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>educativa</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>basada</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>en</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>la</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>exigencia</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>e</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>cc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>innovación</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>conj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>orientada</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>mark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>formar</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>xcomp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>líderes</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>obj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>íntegros</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>que</td>\n",
              "      <td>PRON</td>\n",
              "      <td>PRON</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>transformen</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>acl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Perú</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Text    PoS    TAG    DEP\n",
              "0            La    DET    DET    det\n",
              "1           UPC  PROPN  PROPN  nsubj\n",
              "2            es    AUX    AUX    cop\n",
              "3           una    DET    DET    det\n",
              "4   institución   NOUN   NOUN   ROOT\n",
              "5     educativa    ADJ    ADJ   amod\n",
              "6        basada    ADJ    ADJ   amod\n",
              "7            en    ADP    ADP   case\n",
              "8            la    DET    DET    det\n",
              "9     exigencia   NOUN   NOUN    obj\n",
              "10            e  CCONJ  CCONJ     cc\n",
              "11   innovación   NOUN   NOUN   conj\n",
              "12    orientada    ADJ    ADJ   amod\n",
              "13            a    ADP    ADP   mark\n",
              "14       formar   VERB   VERB  xcomp\n",
              "15            a    ADP    ADP   case\n",
              "16      líderes   NOUN   NOUN    obj\n",
              "17     íntegros   NOUN   NOUN   amod\n",
              "18          que   PRON   PRON  nsubj\n",
              "19  transformen   VERB   VERB    acl\n",
              "20           el    DET    DET    det\n",
              "21         Perú  PROPN  PROPN  nsubj\n",
              "22            .  PUNCT  PUNCT  punct"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc = nlp(\"La UPC es una institución educativa basada en la exigencia e innovación orientada a formar a líderes íntegros que transformen el Perú.\")\n",
        "pos = [[tk.text, tk.pos_, tk.tag_, tk.dep_] for tk in doc]\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(pos, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDlKgSYNekxb"
      },
      "source": [
        "## -Named Entity Recognition (NER)\n",
        "\n",
        "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0TvWjZgekxb",
        "outputId": "6f464ae8-9d06-4686-c370-9b42e090a0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leo Messi - PER - Named person or family.\n",
            "FC Barcelona - ORG - Companies, agencies, institutions, etc.\n",
            "La Liga - MISC - Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Leo Messi exjugador del FC Barcelona marco mas de 400 goles en La Liga\")\n",
        "for entity in doc.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPfD1KQVekxc"
      },
      "source": [
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "# -Resumen\n",
        "\n",
        "* Una vez creado el documento a partir del texto plano, tenemos ese texto tokenizado.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen una serie de propiedades que permiten obtener mucha información relativa a los tokens (o palabras).\n",
        "\n",
        "\n",
        "* Haciendo un resumen de lo visto anteriormente podemos obtener la siguiente información de las palabras de un texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "iFATVvyJekxc",
        "outputId": "9afe905f-f1a6-4552-9bb7-9bf2f588bb3a",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-32dd5068-e2cc-4ec0-bfd8-c601b8487305\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Lema</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>is Stop word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La</td>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>Xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UPC</td>\n",
              "      <td>UPC</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nsubj</td>\n",
              "      <td>XXX</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>es</td>\n",
              "      <td>ser</td>\n",
              "      <td>AUX</td>\n",
              "      <td>AUX</td>\n",
              "      <td>cop</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>una</td>\n",
              "      <td>uno</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>institución</td>\n",
              "      <td>institución</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>educativa</td>\n",
              "      <td>educativo</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>basada</td>\n",
              "      <td>basado</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>la</td>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>exigencia</td>\n",
              "      <td>exigencia</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>obj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>cc</td>\n",
              "      <td>x</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>innovación</td>\n",
              "      <td>innovación</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>conj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>orientada</td>\n",
              "      <td>orientado</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>mark</td>\n",
              "      <td>x</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>formar</td>\n",
              "      <td>formar</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>xcomp</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>x</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>líderes</td>\n",
              "      <td>líder</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>obj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>íntegros</td>\n",
              "      <td>íntegro</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>amod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>que</td>\n",
              "      <td>que</td>\n",
              "      <td>PRON</td>\n",
              "      <td>PRON</td>\n",
              "      <td>nsubj</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>transformen</td>\n",
              "      <td>transformar</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>acl</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>el</td>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Perú</td>\n",
              "      <td>Perú</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>obj</td>\n",
              "      <td>Xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punct</td>\n",
              "      <td>.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32dd5068-e2cc-4ec0-bfd8-c601b8487305')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32dd5068-e2cc-4ec0-bfd8-c601b8487305 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32dd5068-e2cc-4ec0-bfd8-c601b8487305');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ffcadf4-807f-4a62-b10d-4b4a7a2a16f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ffcadf4-807f-4a62-b10d-4b4a7a2a16f7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ffcadf4-807f-4a62-b10d-4b4a7a2a16f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Text         Lema    PoS    TAG    DEP Shape  Alpha  is Stop word\n",
              "0            La           el    DET    DET    det    Xx   True          True\n",
              "1           UPC          UPC  PROPN  PROPN  nsubj   XXX   True         False\n",
              "2            es          ser    AUX    AUX    cop    xx   True          True\n",
              "3           una          uno    DET    DET    det   xxx   True          True\n",
              "4   institución  institución   NOUN   NOUN   ROOT  xxxx   True         False\n",
              "5     educativa    educativo    ADJ    ADJ   amod  xxxx   True         False\n",
              "6        basada       basado    ADJ    ADJ   amod  xxxx   True         False\n",
              "7            en           en    ADP    ADP   case    xx   True          True\n",
              "8            la           el    DET    DET    det    xx   True          True\n",
              "9     exigencia    exigencia   NOUN   NOUN    obj  xxxx   True         False\n",
              "10            e            e  CCONJ  CCONJ     cc     x   True          True\n",
              "11   innovación   innovación   NOUN   NOUN   conj  xxxx   True         False\n",
              "12    orientada    orientado    ADJ    ADJ   amod  xxxx   True         False\n",
              "13            a            a    ADP    ADP   mark     x   True          True\n",
              "14       formar       formar   VERB   VERB  xcomp  xxxx   True         False\n",
              "15            a            a    ADP    ADP   case     x   True          True\n",
              "16      líderes        líder   NOUN   NOUN    obj  xxxx   True         False\n",
              "17     íntegros      íntegro    ADJ    ADJ   amod  xxxx   True         False\n",
              "18          que          que   PRON   PRON  nsubj   xxx   True          True\n",
              "19  transformen  transformar   VERB   VERB    acl  xxxx   True         False\n",
              "20           el           el    DET    DET    det    xx   True          True\n",
              "21         Perú         Perú  PROPN  PROPN    obj  Xxxx   True         False\n",
              "22            .            .  PUNCT  PUNCT  punct     .  False         False"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"La UPC es una institución educativa basada en la exigencia e innovación orientada a formar a líderes íntegros que transformen el Perú.\")\n",
        "\n",
        "result = [[tk.text, tk.lemma_, tk.pos_, tk.tag_, tk.dep_, tk.shape_, tk.is_alpha, tk.is_stop] for tk in doc]\n",
        "pd.DataFrame(result, columns=[\"Text\", \"Lema\", \"PoS\", \"TAG\", \"DEP\", \"Shape\", \"Alpha\", \"is Stop word\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gThaRrDekxc"
      },
      "source": [
        "#### Para más información visitar el siguiente enlace: https://spacy.io/usage/spacy-101#annotations"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
